{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UKB_GenoML_train_discrete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hll4ce/UKB_GenoML/blob/master/UKB_GenoML_train_discrete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UPjKXOr1J3n",
        "colab_type": "text"
      },
      "source": [
        "**Building ML models for every eligible ICD10 Code in the UKBiobank**\n",
        "\n",
        "Authors: Hampton Leonard, Mike Nalls, Faraz Faghri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6JiWcic1Irn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import sys\n",
        "import xgboost\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "\n",
        "# Set the command arguments\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Arguments for training a discrete model in UKB data without making 1000s of *.dataForML files and killing biowulf')    \n",
        "\n",
        "parser.add_argument('--pheno-name', type=str, default='N/A', help='Name of the phenotype to run.')\n",
        "parser.add_argument('--impute-data', type=str, default='median', help='Imputation: (mean, median). Governs secondary imputation and data transformation [default: median].')\n",
        "parser.add_argument('--rank-features', type=str, default='skip', help='Export feature rankings: (skip, run). Exports feature rankings but can be quite slow with huge numbers of features [default: skip].')\n",
        "parser.add_argument('--set-seed', type=str, default='random', help='Sets seed for reproducibility.')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "# set random seed so that results can be reproduced exactly\n",
        "\n",
        "if args.set_seed == \"random\" :\n",
        "    seed = \"random\"\n",
        "else:\n",
        "    seed = int(args.set_seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Here is some basic info on the command you are about to run.\")\n",
        "print(\"Python version info...\")\n",
        "print(sys.version)\n",
        "print(\"CLI argument info...\")\n",
        "print(\"Are you ranking features, even though it is pretty slow? Right now, genoML runs general recursive feature ranking. You chose to\", args.rank_features, \"this part.\")\n",
        "print(\"The imputation method you picked is using the column\", args.impute_data, \"to fill in any remaining NAs.\")\n",
        "print(\"Working with a phenotype with the code ID\", args.pheno_name, \"this is the ICD10 alias in most cases.\")\n",
        "print(\"Your seed is\", seed, \"keep track of this for reproducibility.\")\n",
        "print(\"Give credit where credit is due, for this stage of analysis we use code from the great contributors to python packages: argparse, xgboost, sklearn, pandas, numpy, time, matplotlib and seaborn.\")\n",
        "print(\"As a note, in all exported probabilities and other graphics, case status is treated as a 0 or 1, with 1 representing a positive case. This may differ from your phenotype file input file, if it is coded 1 or 2, but don't worry, genoML will figure it out.\")\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "\n",
        "# Here we set the pheno, cov and geno files. For each batch run, these files should remain constant.\n",
        "\n",
        "pheno_file = \"/data/CARD/projects/UKBB_vs_genoML/parent_code_results/parent_code_UKB_phenos.txt\"\n",
        "covgeno_file = \"/data/LNG/hampton_temp/UKBio/data/merged_cov_geno_final.txt\"\n",
        "pc_file = \"/data/LNG/hampton_temp/UKBio/results_5000/data_pruned_1000_50_0.05.PCA.eigenvec\"\n",
        "\n",
        "\n",
        "\n",
        "# Make dataframe of cases\n",
        "# Read in merged covariate and genotype file, genotypes and other covariates (age,sex,townsend, PCs) should already been merged\n",
        "\n",
        "covsgen = pd.read_csv(covgeno_file, engine = 'c', sep = \" \")\n",
        "\n",
        "# Read in PC's\n",
        "\n",
        "pcs = pd.read_csv(pc_file, engine = 'c', sep = \"\\t\", index_col=False)\n",
        "pcs = pcs[['IID', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5']]\n",
        "\n",
        "\n",
        "# Read in phenos\n",
        "\n",
        "phenos = pd.read_csv(pheno_file, engine = 'c', names = ['ID','ICD'], sep = \"\\t\")\n",
        "\n",
        "# Reduce phenos to IDs in covariate/genotype file\n",
        "\n",
        "phenos_updated = phenos[phenos.ID.isin(covsgen.IID)]\n",
        "\n",
        "# First merge just ID and sex for adjusting some codes that have males in female cods and vice versa\n",
        "\n",
        "check_sex = pd.merge(phenos_updated, covsgen[['IID', 'GENETIC_SEX']], left_on='ID', right_on='IID', how='inner')\n",
        "\n",
        "\n",
        "\n",
        "# Make unique dataframe of samples to sample controls from \n",
        "\n",
        "check_sex_uniq = check_sex.drop_duplicates('ID')\n",
        "\n",
        "\n",
        "pheno = args.pheno_name\n",
        "\n",
        "\n",
        "ICD_to_pull = pheno\n",
        "\n",
        "# Pull out cases that match phenotype argument\n",
        "\n",
        "cases_all = check_sex[check_sex.ICD == ICD_to_pull]\n",
        "\n",
        "\n",
        "# Clean up codes that should be all male or female\n",
        "\n",
        "if(((len(cases_all[(cases_all['GENETIC_SEX'] ==0)])) / len(cases_all['GENETIC_SEX'])) < 0.1 ) :\n",
        "    cases_all = cases_all[cases_all.GENETIC_SEX == 1]\n",
        "elif(((len(cases_all[(cases_all['GENETIC_SEX'] ==1)])) / len(cases_all['GENETIC_SEX'])) < 0.1 ) :\n",
        "    cases_all = cases_all[cases_all.GENETIC_SEX == 0]\n",
        "else: cases_all = cases_all\n",
        "\n",
        "\n",
        "\n",
        "cases_all2 = cases_all\n",
        "\n",
        "\n",
        "\n",
        "# Make stop condition if there are less than 1000 samples and downsample to 2,500 if there are more than 2,500\n",
        "\n",
        "if len(cases_all2.index) < 1000 :\n",
        "    sys.exit(\"You don't have enough samples with the selected phenotype\")\n",
        "    \n",
        "    \n",
        "if len(cases_all2.index) > 2500 :\n",
        "    cases_all = cases_all2.sample(n = 2500)\n",
        "else:\n",
        "    cases_all = cases_all\n",
        "\n",
        "\n",
        "\n",
        "# Turn ICD into pheno column of 0 or 1\n",
        "\n",
        "cases_all.ICD = 1\n",
        "\n",
        "\n",
        "\n",
        "# Merge the newly-created phenotype files with the pre-merged covariate and genotype files\n",
        "\n",
        "covs_cases = pd.merge(cases_all, covsgen, left_on='ID', right_on='IID', how='inner')\n",
        "\n",
        "\n",
        "# Merge with PC's\n",
        "\n",
        "covs_cases = pd.merge(covs_cases, pcs, left_on='IID_y', right_on='IID', how='inner')\n",
        "\n",
        "covs_cases = covs_cases.drop(['FID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE', 'IID_x', 'GENETIC_SEX_x', 'IID', 'IID_y'], axis = 1)\n",
        "\n",
        "\n",
        "# Make controls dataframe\n",
        "\n",
        "# Patients with phenotype cannot be in control dataframe\n",
        "\n",
        "controls = check_sex_uniq[~check_sex_uniq.ID.isin(cases_all2.ID)]  \n",
        "\n",
        "# Make sure if male or female code we are only sampling male or female controls\n",
        "\n",
        "if((covs_cases.loc[:, 'GENETIC_SEX_y'].var()) == 0) :\n",
        "    num = covs_cases.loc[1, 'GENETIC_SEX_y']\n",
        "    controls_sex = controls[controls['GENETIC_SEX'] == num]\n",
        "    if(num == 0):\n",
        "        genderq = \"female\"\n",
        "    else:\n",
        "        genderq = \"male\"\n",
        "else:\n",
        "    controls_sex = controls\n",
        "    genderq = \"both\"\n",
        "\n",
        "\n",
        "# Sample same number of controls as cases\n",
        "\n",
        "number = len(covs_cases.index)\n",
        "\n",
        "controls_sampled = controls_sex.sample(n = number)\n",
        "    \n",
        "# Turn ICD into pheno column of 0 or 1\n",
        "\n",
        "controls_sampled.ICD = 0\n",
        "\n",
        "\n",
        "\n",
        "# Merge control phenotypes with covariate/genotype file\n",
        "\n",
        "covs_controls = pd.merge(controls_sampled, covsgen, left_on='ID', right_on='IID', how='inner')\n",
        "\n",
        "\n",
        "# Merge PC's\n",
        "\n",
        "covs_controls = pd.merge(covs_controls, pcs, left_on='IID_y', right_on='IID', how='inner')\n",
        "\n",
        "covs_controls = covs_controls.drop(['FID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE', 'IID_x', 'GENETIC_SEX_x', 'IID', 'IID_y'], axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "# Combine cases and controls to one dataframe\n",
        "\n",
        "df = covs_cases.append(covs_controls)\n",
        "df = df.reset_index(drop = True)\n",
        "\n",
        "# Drop sex column if all male or female\n",
        "\n",
        "if((df.loc[:, 'GENETIC_SEX_y'].var()) == 0) :\n",
        "    df = df.drop(columns=['GENETIC_SEX_y'])\n",
        "else:\n",
        "    df = df\n",
        "\n",
        "\n",
        "\n",
        "prefix = args.pheno_name\n",
        "\n",
        "\n",
        "\n",
        "# Now impute the missing data\n",
        "\n",
        "impute_type = args.impute_data\n",
        "\n",
        "if impute_type == 'mean': \n",
        "\tdf = df.fillna(df.mean())\n",
        "\n",
        "if impute_type == 'median':\n",
        "\tdf = df.fillna(df.median())\n",
        "\n",
        "\n",
        "# Split the dat into train and test and bank sample IDs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "y = df.ICD\n",
        "X = df.drop(columns=['ICD'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # 70:30\n",
        "IDs_train = X_train.ID\n",
        "IDs_test = X_test.ID\n",
        "\n",
        "\n",
        "X_train = X_train.drop(columns=['ID'])\n",
        "X_test = X_test.drop(columns=['ID'])\n",
        "\n",
        "\n",
        "features = list(X_train.columns) \n",
        "\n",
        "features_outfile =  prefix  + genderq + '.featurenames.csv'\n",
        "\n",
        "features = pd.DataFrame(features)\n",
        "\n",
        "features.to_csv(features_outfile, index=False)\n",
        "\n",
        "# Quick memory reduce by deleting old data\n",
        "\n",
        "print(\"\")\n",
        "print(\"Taking a quick break to take out the garbage and reduce memory consumption!\")\n",
        "import gc\n",
        "del df\n",
        "gc.collect()\n",
        "print(\"\")\n",
        "\n",
        "# Imports\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, log_loss, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "#from sklearn.naive_bayes import ComplementNB - does not work with negative values\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Algorithm list\n",
        "algorithms = [\n",
        "\tLogisticRegression(),\n",
        "\tRandomForestClassifier(),\n",
        "\tAdaBoostClassifier(),\n",
        "\tGradientBoostingClassifier(),\n",
        "\tSGDClassifier(loss='modified_huber'),\n",
        "\tSVC(probability=True),\n",
        "#\tComplementNB(),\n",
        "\tMLPClassifier(),\n",
        "\tKNeighborsClassifier(),\n",
        "\tLinearDiscriminantAnalysis(),\n",
        "\tQuadraticDiscriminantAnalysis(),\n",
        "\tBaggingClassifier(),\n",
        "\tXGBClassifier()\n",
        "\t]\n",
        "# Now lets compete the algorithms!\n",
        "\n",
        "print(\"\")\n",
        "print(\"Now let's compete these algorithms!\")\n",
        "print(\"We'll update you as each algorithm runs, then summarize at the end.\")\n",
        "print(\"Here we test each algorithm under default settings using the same training and test datasets derived from a 70% training and 30% testing split of your data.\")\n",
        "print(\"For each algorithm, we will output the following metrics...\")\n",
        "print(\"Algorithm name, hoping that's pretty self-explanatory. Plenty of resources on these common ML algorithms at https://scikit-learn.org and https://xgboost.readthedocs.io/.\")\n",
        "print(\"AUC_percent, this is the area under the curve from reciever operating characteristic analyses. This is the most common metric of classifier performance in biomedical literature, we express this as a percent. We calculate AUC based on the predicted probability of being a case.\")\n",
        "print(\"Accuracy_percent, this is the simple accuracy of the classifer, how many predictions were correct from best classification cutoff (python default).\")\n",
        "print(\"Balanced_Accuracy_Percent, consider this as the accuracy resampled to a 1:1 mix of cases and controls. Imbalanced datasets can give funny results for simple accuracy.\")\n",
        "print(\"Log_Loss, this is essentially the inverse of the likelihood function for a correct prediction, you want to minimize this.\")\n",
        "print(\"Sensitivity, proportion of cases correcctly identified.\")\n",
        "print(\"Specificity, proportion of controls correctly identified.\")\n",
        "print(\"PPV, this is the positive predictive value, the probability that subjects with a positive result actually have the disease.\")\n",
        "print(\"NPV, this is the negative predictive value, the probability that subjects with a negative result don't have the disease.\")\n",
        "print(\"We also log the runtimes per algorithm.\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Algorithm summaries incoming...\")\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "log_cols=[\"Algorithm\", \"AUC_Percent\", \"Accuracy_Percent\", \"Balanced_Accuracy_Percent\", \"Log_Loss\", \"Sensitivity\", \"Specificity\", \"PPV\", \"NPV\", \"Runtime_Seconds\"]\n",
        "log_table = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "for algo in algorithms:\n",
        "\t\n",
        "\tstart_time = time.time()\n",
        "\t\n",
        "\talgo.fit(X_train, y_train)\n",
        "\tname = algo.__class__.__name__\n",
        "\n",
        "\tprint(\"#\"*30)\n",
        "\tprint(name)\n",
        "\n",
        "\ttest_predictions = algo.predict_proba(X_test)\n",
        "\ttest_predictions = test_predictions[:, 1]\n",
        "\trocauc = roc_auc_score(y_test, test_predictions)\n",
        "\tprint(\"AUC: {:.4%}\".format(rocauc))\n",
        "\n",
        "\ttest_predictions = algo.predict(X_test)\n",
        "\tacc = accuracy_score(y_test, test_predictions)\n",
        "\tprint(\"Accuracy: {:.4%}\".format(acc))\n",
        "\n",
        "\ttest_predictions = algo.predict(X_test)\n",
        "\tbalacc = balanced_accuracy_score(y_test, test_predictions)\n",
        "\tprint(\"Balanced Accuracy: {:.4%}\".format(balacc))\n",
        "\t\n",
        "\tCM = confusion_matrix(y_test, test_predictions)\n",
        "\tTN = CM[0][0]\n",
        "\tFN = CM[1][0]\n",
        "\tTP = CM[1][1]\n",
        "\tFP = CM[0][1]\n",
        "\tsensitivity = TP/(TP+FN)\n",
        "\tspecificity = TN/(TN+FP)\n",
        "\tPPV = TP/(TP+FP)\n",
        "\tNPV = TN/(TN+FN)\n",
        "\t\n",
        "\n",
        "\ttest_predictions = algo.predict_proba(X_test)\n",
        "\tll = log_loss(y_test, test_predictions)\n",
        "\tprint(\"Log Loss: {:.4}\".format(ll))\n",
        "\t\n",
        "\tend_time = time.time()\n",
        "\telapsed_time = (end_time - start_time)\n",
        "\tprint(\"Runtime in seconds: {:.4}\".format(elapsed_time)) \n",
        "\n",
        "\tlog_entry = pd.DataFrame([[name, rocauc*100, acc*100, balacc*100, ll, sensitivity, specificity, PPV, NPV, elapsed_time]], columns=log_cols)\n",
        "\tlog_table = log_table.append(log_entry)\n",
        "\n",
        "print(\"#\"*30)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "log_outfile =  prefix + genderq + '.training_withheldSamples_performanceMetrics.csv'\n",
        "\n",
        "print(\"This table below is also logged as\", log_outfile, \"and is in your current working directory...\")\n",
        "print(\"#\"*30)\n",
        "print(log_table)\n",
        "print(\"#\"*30)\n",
        "\n",
        "log_table.to_csv(log_outfile, index=False)\n",
        "\n",
        "# Save the model with the best AUC. First save the algorithm name for future use, then the model itself.\n",
        "\n",
        "# Saving best performing algorithm name\n",
        "\n",
        "best_performing_summary = log_table[log_table.AUC_Percent == log_table.AUC_Percent.max()]\n",
        "best_algo = best_performing_summary.at[0,'Algorithm']\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Based on your withheld samples, the algorithm with the best AUC is the\", best_algo, \"... lets save that model for you.\")\n",
        "\n",
        "best_algo_name_out = prefix + genderq + '.best_algorithm.txt'\n",
        "file = open(best_algo_name_out,'w')\n",
        "file.write(best_algo)\n",
        "file.close() \n",
        "\n",
        "# Rebuilding best performing model and exporting.\n",
        "\n",
        "# Remeber to pull attributes from text file.\n",
        "\n",
        "if best_algo == 'LogisticRegression':\n",
        "\talgo = getattr(sklearn.linear_model, best_algo)()\n",
        "\n",
        "if  best_algo == 'SGDClassifier':\n",
        "\talgo = getattr(sklearn.linear_model, best_algo)(loss='modified_huber')\n",
        "\n",
        "if (best_algo == 'RandomForestClassifier') or (best_algo == 'AdaBoostClassifier') or (best_algo == 'GradientBoostingClassifier') or  (best_algo == 'BaggingClassifier'):\n",
        "\talgo = getattr(sklearn.ensemble, best_algo)()\n",
        "\n",
        "if best_algo == 'SVC':\n",
        "\talgo = getattr(sklearn.svm, best_algo)(probability=True)\n",
        "\n",
        "if best_algo == 'ComplementNB':\n",
        "\talgo = getattr(sklearn.naive_bayes, best_algo)()\n",
        "\n",
        "if best_algo == 'MLPClassifier':\n",
        "\talgo = getattr(sklearn.neural_network, best_algo)()\n",
        "\n",
        "if best_algo == 'XGBClassifier':\n",
        "\talgo = getattr(xgboost, best_algo)()\n",
        "\n",
        "if best_algo == 'KNeighborsClassifier':\n",
        "\talgo = getattr(sklearn.neighbors, best_algo)()\n",
        "\n",
        "if (best_algo == 'LinearDiscriminantAnalysis') or (best_algo == 'QuadraticDiscriminantAnalysis'):\n",
        "\talgo = getattr(sklearn.discriminant_analysis, best_algo)()\n",
        "\n",
        "algo.fit(X_train, y_train)\n",
        "name = algo.__class__.__name__\n",
        "\n",
        "print(\"...remember, there are occasionally slight fluxuations in model performance on the same withheld samples...\")\n",
        "\n",
        "print(\"#\"*30)\n",
        "\n",
        "print(name)\n",
        "\n",
        "test_predictions = algo.predict_proba(X_test)\n",
        "test_predictions = test_predictions[:, 1]\n",
        "rocauc = roc_auc_score(y_test, test_predictions)\n",
        "print(\"AUC: {:.4%}\".format(rocauc))\n",
        "\n",
        "test_predictions = algo.predict(X_test)\n",
        "acc = accuracy_score(y_test, test_predictions)\n",
        "print(\"Accuracy: {:.4%}\".format(acc))\n",
        "\n",
        "test_predictions = algo.predict(X_test)\n",
        "balacc = balanced_accuracy_score(y_test, test_predictions)\n",
        "print(\"Balanced Accuracy: {:.4%}\".format(balacc))\n",
        "\n",
        "test_predictions = algo.predict_proba(X_test)\n",
        "ll = log_loss(y_test, test_predictions)\n",
        "print(\"Log Loss: {:.4}\".format(ll))\n",
        "\n",
        "# Save it using joblib\n",
        "from joblib import dump, load\n",
        "algo_out = prefix + genderq + '.trainedModel.joblib'\n",
        "dump(algo, algo_out)\n",
        "\n",
        "print(\"#\"*30)\n",
        "\n",
        "print(\"... this model has been saved as\", algo_out, \"for later use and can be found in your working directory.\")\n",
        "## Export the AUC curve in witheld samples.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_out = prefix + genderq + '.trainedModel_withheldSample_ROC.png'\n",
        "\n",
        "test_predictions = algo.predict_proba(X_test)\n",
        "test_predictions = test_predictions[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, test_predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='purple', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='cyan', linestyle='--', label='Chance (area = %0.2f)' % 0.5)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('Receiver operating characteristic (ROC) - ' + best_algo )\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(plot_out, dpi = 600)\n",
        "\n",
        "print()\n",
        "print(\"We are also exporting a ROC curve for you here\", plot_out, \"this is a graphical representation of AUC in the withheld test data for the best performing algorithm.\")\n",
        "# Export predictions separately for training and withheld samples from the test set.\n",
        "\n",
        "# Exporting withheld test data\n",
        "\n",
        "test_predicteds_probs = algo.predict_proba(X_test)\n",
        "test_case_probs = test_predicteds_probs[:, 1]\n",
        "test_predicted_cases = algo.predict(X_test)\n",
        "\n",
        "test_case_probs_df = pd.DataFrame(test_case_probs)\n",
        "test_predicted_cases_df = pd.DataFrame(test_predicted_cases)\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "IDs_test_df = pd.DataFrame(IDs_test)\n",
        "\n",
        "test_out = pd.concat([IDs_test_df.reset_index(), y_test_df.reset_index(drop=True), test_case_probs_df.reset_index(drop=True), test_predicted_cases_df.reset_index(drop=True)], axis = 1, ignore_index=True)\n",
        "test_out.columns=['INDEX','ID',\"CASE_REPORTED\",\"CASE_PROBABILITY\",\"CASE_PREDICTED\"]\n",
        "test_out = test_out.drop(columns=['INDEX'])\n",
        "\n",
        "test_outfile = prefix + genderq + '.trainedModel_withheldSample_Predictions.csv'\n",
        "test_out.to_csv(test_outfile, index=False)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Preview of the exported predictions for the withheld test data that has been exported as\", test_outfile, \"these are pretty straight forward.\")\n",
        "print(\"They generally include the sample ID, the previously reported case status (1 = case), the case probability from the best performing algorithm and the predicted label from that algorithm,\")\n",
        "print(\"#\"*30)\n",
        "print(test_out.head())\n",
        "print(\"#\"*30)\n",
        "\n",
        "\n",
        "# Exporting training data, which is by nature overfit.\n",
        "\n",
        "train_predicteds_probs = algo.predict_proba(X_train)\n",
        "train_case_probs = train_predicteds_probs[:, 1]\n",
        "train_predicted_cases = algo.predict(X_train)\n",
        "\n",
        "train_case_probs_df = pd.DataFrame(train_case_probs)\n",
        "train_predicted_cases_df = pd.DataFrame(train_predicted_cases)\n",
        "y_train_df = pd.DataFrame(y_train)\n",
        "IDs_train_df = pd.DataFrame(IDs_train)\n",
        "\n",
        "train_out = pd.concat([IDs_train_df.reset_index(), y_train_df.reset_index(drop=True), train_case_probs_df.reset_index(drop=True), train_predicted_cases_df.reset_index(drop=True)], axis = 1, ignore_index=True)\n",
        "train_out.columns=['INDEX','ID',\"CASE_REPORTED\",\"CASE_PROBABILITY\",\"CASE_PREDICTED\"]\n",
        "train_out = train_out.drop(columns=['INDEX'])\n",
        "\n",
        "train_outfile = prefix + genderq + '.trainedModel_trainingSample_Predictions.csv'\n",
        "train_out.to_csv(train_outfile, index=False)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Preview of the exported predictions for the traiing samples which is naturally overfit and exported as\", train_outfile, \"in the similar format as in the withheld test dataset that was just exported.\")\n",
        "print(\"#\"*30)\n",
        "print(train_out.head())\n",
        "print(\"#\"*30)\n",
        "\n",
        "# Export histograms of probabilities.\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "genoML_colors = [\"cyan\",\"purple\"]\n",
        "\n",
        "g = sns.FacetGrid(train_out, hue=\"CASE_REPORTED\", palette=genoML_colors, legend_out=True,)\n",
        "g = (g.map(sns.distplot, \"CASE_PROBABILITY\", hist=False, rug=True))\n",
        "g.add_legend()\n",
        "\n",
        "plot_out = prefix + genderq + '.trainedModel_withheldSample_probabilities.png'\n",
        "g.savefig(plot_out, dpi=600)\n",
        "\n",
        "print(\"\")\n",
        "print(\"We are also exporting probability density plots to the file\", plot_out, \"this is a plot of the probability distributions of being a case, stratified by case and control status in the withheld test samples.\")\n",
        "\n",
        "# Export feature ranks.\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "feature_trigger = args.rank_features\n",
        "\n",
        "if (feature_trigger == 'run'):\n",
        "\n",
        "\tif (best_algo == 'SVC') or (best_algo == 'ComplementNB') or (best_algo == 'KNeighborsClassifier') or (best_algo == 'QuadraticDiscriminantAnalysis') or (best_algo == 'BaggingClassifier'):\n",
        "\t\n",
        "\t\tprint(\"Even if you selected to run feature ranking, you can't generate feature ranks using SVC, ComplementNB, KNeighborsClassifier, QuadraticDiscriminantAnalysis or BaggingClassifier... it just isn't possible.\")\n",
        "\t\n",
        "\telse:\n",
        "\t\tprint(\"Processing feature ranks, this can take a while. But you will get a relative rank for every feature in the model.\")\n",
        "\t\n",
        "\t\tfrom sklearn.feature_selection import RFE\n",
        "\n",
        "\t\ttop_ten_percent = (len(X_train)//10)\n",
        "\t\t# core_count = args.n_cores\n",
        "\t\tnames = list(X_train.columns)\n",
        "\t\trfe = RFE(estimator=algo)\n",
        "\t\trfe.fit(X_train, y_train)\n",
        "\t\trfe_out = zip(rfe.ranking_, names)\n",
        "\t\trfe_df = pd.DataFrame(rfe_out, columns = [\"RANK\",\"FEATURE\"])\n",
        "\t\ttable_outfile =  prefix + genderq + '.trainedModel_trainingSample_featureImportance.csv'\n",
        "\t\trfe_df.to_csv(table_outfile, index=False)\n",
        "\t\n",
        "\t\tprint(\"Feature ranks exported as\", table_outfile, \"if you want to be very picky and make a more parsimonious model with a minimal feature set, extract all features ranked 1 and rebuild your dataset. This analysis also gives you a concept of the relative importance of your features in the model.\")\n",
        "\n",
        "print()\n",
        "print(\"Thanks for training a model with GenoML!\")\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}